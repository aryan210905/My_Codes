# -*- coding: utf-8 -*-
"""GradientDescentMultiVariateLR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VRp61psJtd-MJNLdzH-WHao7aTtV_XOR
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
from sklearn.preprocessing import StandardScaler

df= pd.read_csv(r'D:\CODING_CODES\AIML\ML\Supervised\Data\multivariate_linear_regression_data.csv')
df.sample(10)

X = df.drop('Salary',axis=1)
y = df['Salary']

X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.2,random_state=4)

lr = LinearRegression()
lr.fit(X_train, y_train)

bOLS = lr.intercept_
mOLS = lr.coef_
print(bOLS,mOLS)

# m independant columns -> (m+1) parameters
# n = rows

# L = 1/n * sum((y-y')^2) where y' = b0+b1*x1+b2*x2+b3*x3+....+bm*xm
# L = 1/n * sum((y-(b0+b1*x1+b2*x2+b3*x3+....+bm*xm))^2)
# dL/db0 = -2/n * sum((y-y'))
# dL/db1 = -2/n * sum((y-y')*xi1) for i = 1->n
# dL/db2 = -2/n * sum((y-y')*xi2) for i = 1->n
# list of slopes = [ dL/db1, dL/db2,...., dL/dbn ] = -2 * np.dot((y-y'),X)/n
# where i-> particular row

# b0 = b0 - learning_rate*(dL/db0)
# b1 = b1 - learning_rate*(dL/db1)
# b1 = b1 - learning_rate*(dL/db1)

class GD:
  def __init__(self,learning_rate,epochs):
    self.learning_rate = learning_rate
    self.epochs = epochs

  def fit(self,X,y):
    self.m = np.ones(X.shape[1])   # list of slopes initially 1
    self.b0 = 0  # intercept
    n = X.shape[0]
    for i in range(self.epochs):
      yHat = np.dot(X,self.m) + self.b0
      slope_b0 = -2 * np.mean(y-yHat)
      self.b0 = self.b0 - (self.learning_rate*slope_b0)
      slope_m = -2 * np.dot((y-yHat),X)/n
      self.m = self.m - (self.learning_rate*slope_m)
    print(f"\nAfter Gradient Descent: Intercept: {self.b0}, slopes: {self.m}")

  def predict(self,X):
    return np.dot(X,self.m)+self.b0

gdr = GD(0.0001,50000)

gdr.fit(X_train,y_train)

print(bOLS,mOLS)

